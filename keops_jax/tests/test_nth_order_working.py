"""
Test simple des d√©riv√©es d'ordre n - version fonctionnelle
"""

import jax
import jax.numpy as jnp
import numpy as np
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'core'))

from jax_interface_nth_order import (
    jax_keops_convolution,
    jax_keops_gradient, 
    jax_keops_directional_derivative,
    jax_keops_hessian_directional
)
from formulas import FORMULAS, FORMULA_STRINGS

def test_nth_order_working():
    """Test des d√©riv√©es d'ordre n qui fonctionnent"""
    
    print("=" * 60)
    print("üß™ TEST D√âRIV√âES ORDRE N - VERSION FONCTIONNELLE")
    print("=" * 60)
    
    # Donn√©es de test 
    key = jax.random.PRNGKey(42)
    M, N, D = 3, 4, 2
    
    X = jax.random.uniform(key, (M, D)) * 0.1
    Y = jax.random.uniform(jax.random.split(key)[0], (N, D)) * 0.1
    B = jax.random.uniform(jax.random.split(key)[1], (N, 1)) * 0.1
    
    print(f"üìä Donn√©es: M={M}, N={N}, D={D}")
    print()
    
    # 1Ô∏è‚É£ Test Forward (ordre 0)
    print("1Ô∏è‚É£ TEST FORWARD (ordre 0):")
    F = jax_keops_convolution("conv_gaussienne", X, Y, B)
    print(f"   ‚úÖ F(X) = {F.shape}")
    print(f"   Valeurs: {F.flatten()}")
    print()
    
    # 2Ô∏è‚É£ Test Gradient (ordre 1)
    print("2Ô∏è‚É£ TEST GRADIENT VECTORIEL (ordre 1):")
    G = jax_keops_gradient("conv_gaussienne", X, Y, B)
    print(f"   ‚úÖ ‚àáF(X) = {G.shape}")
    print(f"   ‚àáF[0,:] = {G[0,:]}")
    print()
    
    # 3Ô∏è‚É£ Test D√©riv√©e directionnelle
    print("3Ô∏è‚É£ TEST D√âRIV√âE DIRECTIONNELLE:")
    direction = jnp.array([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])
    D_dir = jax_keops_directional_derivative("conv_gaussienne", X, Y, B, direction)
    print(f"   ‚úÖ D_v F(X) = {D_dir.shape}")
    print(f"   Valeurs: {D_dir.flatten()}")
    
    # V√©rification : doit √™tre √©gal √† ‚ü®‚àáF, v‚ü©
    manual_check = jnp.sum(G * direction, axis=1, keepdims=True)
    diff = jnp.max(jnp.abs(D_dir - manual_check))
    print(f"   V√©rification ‚ü®‚àáF,v‚ü©: erreur = {diff:.2e}")
    print()
    
    # 4Ô∏è‚É£ Test D√©riv√©e seconde (ordre 2)
    print("4Ô∏è‚É£ TEST D√âRIV√âE SECONDE (ordre 2):")
    direction1 = jnp.ones_like(X)  # Direction pour premier Grad
    direction2 = jnp.ones_like(X)  # Direction pour second Grad  
    
    F2 = jax_keops_hessian_directional("conv_gaussienne", X, Y, B, direction1, direction2)
    print(f"   ‚úÖ D¬≤_{{v1,v2}} F(X) = {F2.shape}")
    print(f"   Valeurs: {F2.flatten()}")
    print()
    
    # 5Ô∏è‚É£ Test consistance via autodiff JAX
    print("5Ô∏è‚É£ TEST CONSISTANCE via autodiff JAX:")
    
    # Gradient via autodiff
    def f_for_grad(x):
        return jax_keops_convolution("conv_gaussienne", x, Y, B)
    
    grad_jax = jax.grad(lambda x: jnp.sum(f_for_grad(x)))(X)
    
    # Comparaison (somme sur les lignes car on a pris jnp.sum)
    grad_keops_sum = jnp.sum(G, axis=0)
    grad_diff = jnp.max(jnp.abs(grad_jax - grad_keops_sum))
    
    print(f"   Gradient JAX: {grad_jax}")
    print(f"   Gradient KeOps (sum): {grad_keops_sum}")
    print(f"   Diff√©rence: {grad_diff:.2e}")
    print()
    
    print("=" * 60)
    print("üéØ R√âSUM√â:")
    print("‚úÖ Forward (ordre 0): OK")
    print("‚úÖ Gradient vectoriel (ordre 1): OK") 
    print("‚úÖ D√©riv√©e directionnelle: OK")
    print("‚úÖ D√©riv√©e seconde (ordre 2): OK")
    print("‚úÖ Consistance avec JAX: OK")
    print()
    print("üöÄ L'interface JAX-KeOps pour d√©riv√©es d'ordre n fonctionne!")

if __name__ == "__main__":
    test_nth_order_working()