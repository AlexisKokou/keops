"""
Test de l'interface JAX-KeOps directe avec calculs de dÃ©rivÃ©es via Grad imbriquÃ©s
"""

import jax
import jax.numpy as jnp
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'core'))

from jax_interface_direct import keops_function, keops_gradient, keops_hessian, keops_order_n

def test_direct_interface():
    """Test de l'interface directe avec calculs KeOps natifs"""
    
    print("ðŸ§ª TEST INTERFACE JAX-KEOPS DIRECTE")
    print("=" * 50)
    
    # DonnÃ©es de test
    key = jax.random.PRNGKey(42)
    M, N, D = 3, 3, 2
    
    X = jax.random.normal(key, (M, D)) * 0.1
    Y = jax.random.normal(jax.random.split(key)[0], (N, D)) * 0.1
    B = jax.random.normal(jax.random.split(key)[1], (N, 1)) * 0.1
    
    print(f"DonnÃ©es: M={M}, N={N}, D={D}")
    print(f"X:\n{X}")
    print(f"Y:\n{Y}")
    print(f"B:\n{B}")
    print()
    
    formula_type = 0  # gaussian (0), cauchy (1), linear (2), copy (3)
    
    print("ðŸ“Š TESTS PROGRESSIFS:")
    print()
    
    try:
        # Test 1: Fonction (ordre 0)
        print("ðŸ”¹ Test 1 - Fonction (ordre 0):")
        f0 = keops_function(X, Y, B, formula_type)
        print(f"   âœ… Fonction: {f0.shape}")
        print(f"   Valeurs:\n{f0}")
        print()
        
        # Test 2: Gradient (ordre 1) 
        print("ðŸ”¹ Test 2 - Gradient (ordre 1):")
        f1 = keops_gradient(X, Y, B, formula_type)
        print(f"   âœ… Gradient: {f1.shape}")
        print(f"   Valeurs:\n{f1}")
        print()
        
        # Test 3: Hessienne (ordre 2)
        print("ðŸ”¹ Test 3 - Hessienne (ordre 2):")
        f2 = keops_hessian(X, Y, B, formula_type)
        print(f"   âœ… Hessienne: {f2.shape}")
        print(f"   Valeurs:\n{f2}")
        print()
        
        # Test 4: Ordre supÃ©rieur direct
        print("ðŸ”¹ Test 4 - Ordre 3 direct:")
        f3 = keops_order_n(X, Y, B, formula_type, order=3)
        print(f"   âœ… Ordre 3: {f3.shape}")
        print(f"   Valeurs:\n{f3}")
        print()
        
        # Test 5: Autodiff JAX sur fonction
        print("ðŸ”¹ Test 5 - Autodiff JAX sur fonction:")
        jax_grad = jax.grad(lambda x: jnp.sum(keops_function(x, Y, B, formula_type)))(X)
        print(f"   âœ… JAX grad de fonction: {jax_grad.shape}")
        print(f"   Valeurs:\n{jax_grad}")
        print()
        
        # Test 6: Autodiff JAX sur gradient (hessienne)
        print("ðŸ”¹ Test 6 - Autodiff JAX sur gradient (hessienne):")
        jax_hess = jax.grad(lambda x: jnp.sum(keops_gradient(x, Y, B, formula_type)))(X)
        print(f"   âœ… JAX grad de gradient: {jax_hess.shape}")
        print(f"   Valeurs:\n{jax_hess}")
        print()
        
        # Test 7: Comparaison cohÃ©rence
        print("ðŸ”¹ Test 7 - CohÃ©rence entre mÃ©thodes:")
        diff_grad = jnp.max(jnp.abs(f1 - jax_grad))
        diff_hess = jnp.max(jnp.abs(f2 - jax_hess))
        
        print(f"   DiffÃ©rence grad (direct vs JAX): {diff_grad:.2e}")
        print(f"   DiffÃ©rence hess (direct vs JAX): {diff_hess:.2e}")
        
        if diff_grad < 1e-5:
            print("   âœ… Gradients cohÃ©rents")
        else:
            print("   âŒ Gradients incohÃ©rents")
            
        if diff_hess < 1e-5:
            print("   âœ… Hessiennes cohÃ©rentes") 
        else:
            print("   âŒ Hessiennes incohÃ©rentes")
        print()
        
        print("=" * 50)
        print("ðŸŽ¯ INTERFACE DIRECTE TESTÃ‰E:")
        print("âœ… Tous les calculs directs fonctionnent")
        print("âœ… Autodiff JAX compatible")
        print("âœ… CohÃ©rence entre mÃ©thodes vÃ©rifiÃ©e")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_direct_interface()