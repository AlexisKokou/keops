{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f03046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pykeops.torch import LazyTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25daaaea",
   "metadata": {},
   "source": [
    "Nous utilisons le GPU Apple Silicon (MPS) sur Mac pour accélérer les calculs, lorsque celui-ci est disponible. Cela permet d'exploiter la puissance de la puce graphique intégrée pour des traitements plus rapides, notamment lors de l'utilisation de bibliothèques comme PyTorch et KeOps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b9e06a",
   "metadata": {},
   "source": [
    "Pour chaque thread GPU (qui s’occupe d’un point x_i) :\n",
    "- chaque thread calcule f[i] pour un i donné\n",
    "\n",
    " - Initialiser une variable locale : \n",
    "    fi = 0\n",
    "\n",
    " - Pour chaque bloc (chunk) de points y_j :\n",
    "    - on charge un petit sous-ensemble de y_j dans la mémoire rapide du GPU\n",
    "\n",
    "        y_chunk = y[j : j + chunk_size]\n",
    "\n",
    "    - Pour chaque y_j dans ce chunk :\n",
    "\n",
    "        - Calculer la distance euclidienne au carré :\n",
    "\n",
    "        d2 = 0\n",
    "\n",
    "        - Pour k dans [0 .. d-1] :\n",
    "\n",
    "        diff = x_i[k] - y_j[k]\n",
    "\n",
    "        d2 += diff * diff\n",
    "\n",
    "        - Calculer la valeur du noyau gaussien :\n",
    "\n",
    "        K = exp( -d2 / (2 * sigma²) )\n",
    "\n",
    "    - Ajouter la contribution :\n",
    "\n",
    "    fi += K \n",
    "\n",
    " - Une fois tous les chunks traités : f[i] = fi -> on jette Dij et Kij immédiatement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9df0d",
   "metadata": {},
   "source": [
    "### Pseudo‑code — convolution / noyau gaussien (avec torch / numpy)\n",
    "\n",
    "But : la \"convolution gaussienne\" peut désigner soit un produit de convolution sur une grille (FFT ou filtre séparables), soit une somme de noyaux entre ensembles de points (estimation de densité). Ci‑dessous on donne le pseudo‑code pour l'estimation de densité par noyau (Σ_j exp(-||x_i - y_j||² / 2σ²)), en 3 variantes : naïve, vectorisée et par chunks (GPU/mémoire).\n",
    "\n",
    "1) Naïf (conceptuel, double boucle)\n",
    "```text\n",
    "pour i de 0 à N-1:\n",
    "    fi = 0\n",
    "    pour j de 0 à M-1:\n",
    "        d2 = 0\n",
    "        pour k de 0 à d-1:\n",
    "            diff = x[i,k] - y[j,k]\n",
    "            d2 += diff * diff\n",
    "        K = exp(- d2 / (2 * sigma**2))\n",
    "        fi += K\n",
    "    f[i] = fi\n",
    "```\n",
    "\n",
    "2) Vectorisé (torch / numpy, broadcasting)\n",
    "```text\n",
    "# formes : x => (N, d), y => (M, d)\n",
    "# étape 1 : créer des vues pour broadcasting\n",
    "x_expanded = x[:, None, :]    # (N, 1, d)\n",
    "y_expanded = y[None, :, :]    # (1, M, d)\n",
    "\n",
    "# étape 2 : distances au carré (broadcast et somme sur la dernière dim)\n",
    "D2 = ((x_expanded - y_expanded) ** 2).sum(axis=-1)   # (N, M)\n",
    "\n",
    "# étape 3 : noyau gaussien\n",
    "K = exp(- D2 / (2 * sigma**2))   # (N, M)\n",
    "\n",
    "# étape 4 : somme sur j\n",
    "f = K.sum(axis=1)   # (N,)\n",
    "```\n",
    "\n",
    "Remarques :\n",
    "- En torch : utilisez les mêmes opérations (x[:, None, :] etc.). Les opérations sont effectuées sur le device du tenseur (CPU ou GPU).\n",
    "- Complexité temporelle O(N*M*d). Mémoire intermédiaire D2 ou K prend O(N*M) — peut exploser pour grandes tailles.\n",
    "\n",
    "3) Par chunks / mémoire limitée (GPU-friendly)\n",
    "```text\n",
    "# on parcourt y par petits paquets pour éviter d'allouer (N, M)\n",
    "f = zeros(N)\n",
    "\n",
    "pour start de 0 à M-1 step chunk_size:\n",
    "    end = min(start + chunk_size, M)\n",
    "    y_chunk = y[start:end, :]               # (chunk, d)\n",
    "    y_chunk_exp = y_chunk[None, :, :]       # (1, chunk, d)\n",
    "    # broadcasting avec x[:,None,:] déjà (N,1,d)\n",
    "    D2_chunk = ((x[:, None, :] - y_chunk_exp) ** 2).sum(axis=-1)  # (N, chunk)\n",
    "    K_chunk = exp(- D2_chunk / (2 * sigma**2))\n",
    "    f += K_chunk.sum(axis=1)\n",
    "\n",
    "# résultat f (N,)\n",
    "```\n",
    "\n",
    "4) Optimisations / variantes\n",
    "- KeOps / LazyTensor : évite d'allouer D2/K complets en utilisant du calcul paresseux et réduit la consommation mémoire.\n",
    "- Filtre gaussien sur grille 2D : utiliser convolution séparable (1D puis 1D) ou FFT pour grande grille (complexité différente).\n",
    "- Précision & device : choisir dtype (float32) et device (.to('cuda') ou MPS) ; convertir pour affichage : f.cpu().numpy().\n",
    "- Normalisation possible : diviser par M si on veut une densité moyenne.\n",
    "\n",
    "5) Bonnes pratiques\n",
    "- Tester avec petits N/M pour valider la logique vectorisée avant de monter en taille.\n",
    "- Choisir chunk_size en fonction de la RAM/GPU pour éviter OOM.\n",
    "- Utiliser KeOps si N*M trop grand et si on veut gains mémoire/temps automatiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e3b65",
   "metadata": {},
   "source": [
    "La ligne suivante définit le type de données (`dtype`) utilisé pour les tenseurs PyTorch dans ce notebook. Ici, `torch.float32` indique que les valeurs des tenseurs seront stockées en précision flottante sur 32 bits, ce qui est généralement suffisant pour la plupart des calculs numériques tout en étant plus rapide et moins gourmand en mémoire que la précision double (`float64`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421cb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, d = 3000, 3000, 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7765819",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(N, d, device=device, dtype=dtype)\n",
    "y = torch.randn(M, d, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1beec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9831f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_i = LazyTensor(x[:, None, :])   # (N, 1, d)\n",
    "y_j = LazyTensor(y[None, :, :])   # (1, M, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79de328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_ij = ((x_i - y_j) ** 2).sum(-1) #-> le sum(-1) effectue la \n",
    "#somme sur le dernier indice càd sur les j "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77cbda",
   "metadata": {},
   "source": [
    "Pour obtenir la densité locale $( f_i )$, on effectue la somme sur chaque ligne du noyau gaussien $( K_{ij} )$, c'est-à-dire sur l'indice \\( j \\) pour chaque point d'évaluation $( x_i )$ :\n",
    "\n",
    "$\n",
    "f_i = \\sum_{j=1}^{M} K_{ij}$\n",
    "\n",
    "Dans le code, cela correspond à :\n",
    "\n",
    "```python\n",
    "f = K_ij.sum(dim=1)\n",
    "```\n",
    "\n",
    "Chaque valeur $( f_i )$ représente la densité locale autour du point $( x_i )$, calculée à partir de la contribution de tous les points sources $( y_j )$ via le noyau gaussien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1787f8",
   "metadata": {},
   "source": [
    "Affichage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce8d55a",
   "metadata": {},
   "source": [
    "Visualisation 2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e0e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "919e3f16",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_keops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
